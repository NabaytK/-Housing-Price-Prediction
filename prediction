# ðŸ”¹ Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# ðŸ”¹ Step 2: Load Dataset
df = pd.read_csv("housing.csv")

# ðŸ”¹ Step 3: Handle Missing Values (All Columns)
for col in df.columns:
    if df[col].isnull().any():
        if df[col].dtype in ['int64', 'float64']:
            df[col].fillna(df[col].median(), inplace=True)
        else:
            df[col].fillna(df[col].mode()[0], inplace=True)

# ðŸ”¹ Step 4: Convert Categorical Column to Numeric
df = pd.get_dummies(df, columns=["ocean_proximity"], drop_first=True)

# ðŸ”¹ Step 5: Define Features and Target
X = df.drop("median_house_value", axis=1)
y = df["median_house_value"]

# ðŸ”¹ Step 6: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ðŸ”¹ Step 7: Create Pipeline with Scaling and Model
model = make_pipeline(StandardScaler(), LinearRegression())
model.fit(X_train, y_train)

# ðŸ”¹ Step 8: Make Predictions
y_pred = model.predict(X_test)

# ðŸ”¹ Step 9: Evaluate Model Performance
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
cv_scores = cross_val_score(model, X, y, cv=5, scoring="r2")

print(f"âœ… RMSE: {rmse:.2f}")
print(f"âœ… RÂ² Score: {r2:.2f}")
print(f"âœ… Cross-Validated RÂ²: {cv_scores.mean():.2f} (Â±{cv_scores.std():.2f})")

# ðŸ”¹ Step 10: Advanced Visualizations
plt.figure(figsize=(18, 12))

# 1. Actual vs Predicted Prices
plt.subplot(2, 2, 1)
sns.regplot(x=y_test, y=y_pred, line_kws={"color": "red"})
plt.xlabel("Actual Prices ($)", fontsize=12)
plt.ylabel("Predicted Prices ($)", fontsize=12)
plt.title("Actual vs Predicted Prices", fontsize=14)
plt.grid(alpha=0.3)

# 2. Residual Plot
plt.subplot(2, 2, 2)
residuals = y_test - y_pred
sns.scatterplot(x=y_pred, y=residuals, alpha=0.6)
plt.axhline(y=0, color="red", linestyle="--")
plt.xlabel("Predicted Prices ($)", fontsize=12)
plt.ylabel("Residuals ($)", fontsize=12)
plt.title("Residual Analysis", fontsize=14)
plt.grid(alpha=0.3)

# 3. Error Distribution
plt.subplot(2, 2, 3)
sns.histplot(residuals, kde=True, bins=30)
plt.xlabel("Prediction Error ($)", fontsize=12)
plt.title("Error Distribution", fontsize=14)
plt.grid(alpha=0.3)

# 4. Feature Importance
plt.subplot(2, 2, 4)
coefficients = model.named_steps["linearregression"].coef_
features = X.columns
sns.barplot(x=coefficients, y=features, palette="viridis")
plt.xlabel("Coefficient Value", fontsize=12)
plt.title("Feature Importance", fontsize=14)
plt.grid(alpha=0.3)

plt.tight_layout()
plt.show()

# ðŸ”¹ Bonus: Prediction Error Analysis
error_df = pd.DataFrame({
    "Actual": y_test,
    "Predicted": y_pred,
    "Error": residuals,
    "Percent Error": (residuals/y_test)*100
}).reset_index(drop=True)

print("\nðŸ“Š Top 10 Prediction Errors:")
print(error_df.nlargest(10, "Error").round(2))
